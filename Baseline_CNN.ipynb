{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxrvRO0PsQKz"
      },
      "source": [
        "# Import Neccessary Libraries:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import time\n",
        "from PIL import Image\n",
        "from torchsummary import summary\n",
        "import time"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njosZkHIsU1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1de3ef-8f7d-4382-b93a-33256c04c445"
      },
      "source": [
        "# To mount drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwesD_cpsU3u",
        "outputId": "b0490e55-9950-4709-b4ad-7dd9d8d762ef"
      },
      "source": [
        "# Checking GPU:\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPa3CiuSW-WL",
        "outputId": "53590941-5073-4b1e-9437-3b5f09700e80"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY5oOLFQS09Z"
      },
      "source": [
        "def get_data_from_drive(copy = True, extract = True):\n",
        "  start = time.time()\n",
        "  if copy:\n",
        "    print(\"Copying Train Source from Drive.\")\n",
        "    !cp \"/content/drive/MyDrive/DS5500 Data/nasa_tropical_storm_competition_train_source.tar\" -r \"/content/nasa_tropical_storm_competition_train_source.tar\"\n",
        "    print(\"Copying Test Source from Drive.\")\n",
        "    !cp \"/content/drive/MyDrive/DS5500 Data/nasa_tropical_storm_competition_test_source.tar\" -r \"/content/nasa_tropical_storm_competition_test_source.tar\"\n",
        "    print(\"Copying Train Metadata from Drive.\")\n",
        "    !cp \"/content/drive/MyDrive/DS5500 Data/train.csv\" -r \"/content/train.csv\"\n",
        "    print(\"Copying Test Metadata from Drive.\")\n",
        "    !cp \"/content/drive/MyDrive/DS5500 Data/test.csv\" -r \"/content/test.csv\"\n",
        "\n",
        "  if extract:\n",
        "    print(\"Extracting Training Images\")\n",
        "    !tar -xvf \"/content/nasa_tropical_storm_competition_train_source.tar\" -C \"/content/\"\n",
        "    print(\"Extracting Test Images\")\n",
        "    !tar -xvf \"/content/nasa_tropical_storm_competition_test_source.tar\" -C \"/content/\"\n",
        "  \n",
        "  print(\"Data Ready! Time Taken: {:.4f}s\".format(time.time() - start))\n",
        "\n",
        "  \n",
        "def get_image_paths(data, image_dir, folder_name):\n",
        "    data[\"image_path\"] = image_dir + \"/\" + folder_name + \"_\" + data[\"image_id\"] + \"/\" + \"image.jpg\"\n",
        "    data = data[data.columns[[0, 2, 5, 1, 3, 4]]]\n",
        "    return data\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTkh778Kaiwl"
      },
      "source": [
        "def write_model_losses(filename, losses):\n",
        "  print(\"Saving model losses to drive.\")\n",
        "  with open(\"/content/drive/MyDrive/DS5500 Data/{}.pkl\".format(filename), \"wb\") as f:\n",
        "    pickle.dump(losses, f)\n",
        "    \n",
        "\n",
        "def plot_predictions(wind_speed, metadata):\n",
        "    sample_img = metadata[metadata.wind_speed == wind_speed][[\"image_path\",\"predictions\"]].iloc[:5]\n",
        "    for i,img in enumerate(sample_img.image_path):\n",
        "        # im = Image.open(img) \n",
        "        # im.show(title = sample_img[\"predictions\"].iloc[i])\n",
        "        image = mpimg.imread(img)\n",
        "        plt.title(\"Actual: \"+ str(wind_speed) +\"   Predicted: \" + str(round(sample_img[\"predictions\"].iloc[i],2)))\n",
        "        plt.imshow(image, cmap = \"gray\")\n",
        "        plt.show()\n",
        "    return \n",
        "\n",
        "def loadModel(model_path, model = None):\n",
        "  state_dict = torch.load(model_path)\n",
        "  model.load_state_dict(state_dict)\n",
        "  return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxHjOFjvyd1y"
      },
      "source": [
        "class HurricaneImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, metadata, transforms):\n",
        "        self.metadata = metadata\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "\n",
        "        image_path = self.metadata[\"image_path\"][index]\n",
        "        # hurricane_image = io.imread(image_path)\n",
        "        hurricane_image = Image.open(image_path)\n",
        "        label = self.metadata[\"wind_speed\"][index]\n",
        "\n",
        "        if self.transforms:\n",
        "            hurricane_image = self.transforms(hurricane_image)\n",
        "\n",
        "        return hurricane_image, label"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHRS73Dqao13"
      },
      "source": [
        "class BaselineCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaselineCNN, self).__init__()\n",
        "        # convolutional layer\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 5, stride=1, padding=2)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 5, stride=1, padding=2)\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128*14*14, 32)\n",
        "        self.output = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-iK_WpjatXP"
      },
      "source": [
        "def train(model, trainloader, validloader, epochs, criterion, optimizer, device, model_name, losses_filename):\n",
        "\n",
        "  valid_loss_min = np.Inf\n",
        "  losses = {\"train_loss\": [], \"valid_loss\": []}\n",
        "  start = time.time()\n",
        "\n",
        "  for e in range(1, epochs + 1):\n",
        "    train_loss, valid_loss = 0.0, 0.0\n",
        "\n",
        "    # Training the model:\n",
        "    model.train()\n",
        "    for data, target in trainloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        target = target.float().unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # print(\"Size: {}\".format(output.size()))\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        # print(loss)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "\n",
        "    # Validating the model:\n",
        "    model.eval()\n",
        "    for data, target in validloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        target = target.float().unsqueeze(1)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "    train_loss = train_loss / len(trainloader.dataset)\n",
        "    losses[\"train_loss\"].append(train_loss)\n",
        "    valid_loss = valid_loss / len(validloader.dataset)\n",
        "    losses[\"valid_loss\"].append(valid_loss)\n",
        "\n",
        "    print(\"Epoch: {}/{}, Train Loss: {:.5f}, Validation Loss: {:.5f}\".format(e, epochs, train_loss, valid_loss))\n",
        "\n",
        "\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Decrease in Validation Loss: ({:.6f} to {:.6f}). Saving Model...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/DS5500 Data/{}.pt\".format(model_name))\n",
        "        valid_loss_min = valid_loss\n",
        "    \n",
        "  end = time.time()\n",
        "  hours, rem = divmod(end-start, 3600)\n",
        "  minutes, seconds = divmod(rem, 60)\n",
        "  print(\"\\nTime Taken for Training: {:0>2}:{:0>2}:{:05.2f}\\n\".format(int(hours),int(minutes),seconds))\n",
        "  write_model_losses(losses_filename, losses)\n",
        "    \n",
        "  return losses "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib8Jwma6avyH"
      },
      "source": [
        "def model_evaluation(dataloader, model, criterion, device):\n",
        "    # specify loss function\n",
        "    predictions = torch.FloatTensor().cpu()\n",
        "    # criterion = nn.MSELoss()\n",
        "    total_MSE_loss, total_RMSE_loss = 0.0, 0.0\n",
        "    # specify optimizer\n",
        "    # optimizer = optim.Adam(model.parameters(), lr = 0.015)\n",
        "    model.eval()\n",
        "    # for data, target in validloader:\n",
        "    #     data, target = data.to(device), target.to(device)\n",
        "    #     target = target.float().unsqueeze(1)\n",
        "    #     output = model(data)\n",
        "    #     loss = criterion(output, target)\n",
        "    #     valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "    for data, target in dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        target = target.float().unsqueeze(1)\n",
        "        output = model(data)\n",
        "        predictions = torch.cat((predictions, output.cpu()), 0)\n",
        "        print(predictions)\n",
        "        #RMSE\n",
        "        MSE_loss = criterion(output, target)\n",
        "        RMSE_loss = torch.sqrt(MSE_loss)\n",
        "        total_MSE_loss += MSE_loss.item()*data.size(0)\n",
        "        total_RMSE_loss += RMSE_loss.item()*data.size(0)\n",
        "    total_MSE_loss = total_MSE_loss / len(dataloader.dataset)\n",
        "    total_RMSE_loss = total_RMSE_loss / len(dataloader.dataset)\n",
        "\n",
        "  # pass entire testloader, get outputs and append to test_metadata\n",
        "    preds_df = pd.DataFrame(predictions, columns = ['predictions']).astype(\"float\")\n",
        "    return preds_df, total_MSE_loss, total_RMSE_loss"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPidG-7NTrW5"
      },
      "source": [
        "get_data_from_drive(copy = True, extract = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEFKkHAMuAqf"
      },
      "source": [
        "rs = np.random.RandomState(111) # creating a random state for reproducibility of random generators\n",
        "data_dir = \"/content/\"\n",
        "train_metadata = pd.read_csv(\"{}/train.csv\".format(data_dir))\n",
        "test_metadata = pd.read_csv(\"{}/test.csv\".format(data_dir))\n",
        "msk = rs.rand(len(train_metadata)) < 0.8\n",
        "train_metadata2 = train_metadata[msk].reset_index().drop(\"index\", axis=1)\n",
        "valid_metadata = train_metadata[~msk].reset_index().drop(\"index\", axis=1)\n",
        "\n",
        "train_folder_name = \"nasa_tropical_storm_competition_train_source\"\n",
        "test_folder_name = \"nasa_tropical_storm_competition_test_source\"\n",
        "train_image_dir = \"{}/{}\".format(data_dir, train_folder_name)\n",
        "test_image_dir = \"{}/{}\".format(data_dir, test_folder_name)\n",
        "\n",
        "train_metadata2 = get_image_paths(train_metadata2, train_image_dir, train_folder_name)\n",
        "test_metadata = get_image_paths(test_metadata, test_image_dir, test_folder_name)\n",
        "valid_metadata = get_image_paths(valid_metadata, train_image_dir, train_folder_name)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn2EwS-scvIq",
        "outputId": "203dc8d8-7c67-4b2f-ae26-42353b359154"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "pd.set_option(\"display.max_rows\", 100000)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw_qoqfwuwbf"
      },
      "source": [
        "pd.DataFrame(train_metadata.wind_speed.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPMWG4LBzM-T",
        "outputId": "601a71bc-843c-4aa6-a55d-29ff449efb60"
      },
      "source": [
        "valid_metadata.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14149, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9BE4mP7zRdS"
      },
      "source": [
        "# train_metadata2[[\"image_id\", \"image_path\"]]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC-LCxx_yXqz"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        # transforms.RandomResizedCrop(224),\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize([0.5], [0.5])\n",
        "])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxKjeDbKyiE3"
      },
      "source": [
        "trainset = HurricaneImageDataset(train_metadata2, transform)\n",
        "testset = HurricaneImageDataset(test_metadata, transform)\n",
        "validset = HurricaneImageDataset(valid_metadata, transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=256, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=256, shuffle=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16CIvh7DyyWf",
        "outputId": "bb3367bc-c35e-414b-d7c2-d88b84fe1be9"
      },
      "source": [
        "model = BaselineCNN()\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaselineCNN(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=25088, out_features=32, bias=True)\n",
            "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpbZW-uy0ze",
        "outputId": "980ab1b2-a9a1-4b22-e796-b032a6050f19"
      },
      "source": [
        "summary(model, (1, 224, 224))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]             416\n",
            "         MaxPool2d-2         [-1, 16, 112, 112]               0\n",
            "            Conv2d-3         [-1, 32, 112, 112]          12,832\n",
            "         MaxPool2d-4           [-1, 32, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          51,264\n",
            "         MaxPool2d-6           [-1, 64, 28, 28]               0\n",
            "            Conv2d-7          [-1, 128, 28, 28]         204,928\n",
            "         MaxPool2d-8          [-1, 128, 14, 14]               0\n",
            "           Dropout-9                [-1, 25088]               0\n",
            "           Linear-10                   [-1, 32]         802,848\n",
            "          Dropout-11                   [-1, 32]               0\n",
            "           Linear-12                    [-1, 1]              33\n",
            "================================================================\n",
            "Total params: 1,072,321\n",
            "Trainable params: 1,072,321\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 14.55\n",
            "Params size (MB): 4.09\n",
            "Estimated Total Size (MB): 18.83\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISEN55LAy2nR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c686f20b-e8ef-4fb4-f108-3cea587b6584"
      },
      "source": [
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "print(\"Loss Function:\\n\", criterion)\n",
        "# Optimizer\n",
        "print(\"\")\n",
        "# optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
        "print(\"Optimizer:\\n\", optimizer)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Function:\n",
            " MSELoss()\n",
            "\n",
            "Optimizer:\n",
            " SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.0001\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5wELZwbB04"
      },
      "source": [
        "epochs = 50\n",
        "model_name = \"baseline_CNN_SGD\"\n",
        "losses_filename = \"{}_losses\".format(model_name)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrNW8GGO0KfS",
        "outputId": "193bc69d-4edd-4cf2-ae03-36bfb86c0974"
      },
      "source": [
        "model_losses = train(model, trainloader, validloader, epochs, criterion, optimizer, device, model_name, losses_filename)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/50, Train Loss: 3859.13951, Validation Loss: 3022.25798\n",
            "Decrease in Validation Loss: (inf to 3022.257976). Saving Model...\n",
            "Epoch: 2/50, Train Loss: 2941.76327, Validation Loss: 2827.45270\n",
            "Decrease in Validation Loss: (3022.257976 to 2827.452702). Saving Model...\n",
            "Epoch: 3/50, Train Loss: 2754.40506, Validation Loss: 2649.00298\n",
            "Decrease in Validation Loss: (2827.452702 to 2649.002981). Saving Model...\n",
            "Epoch: 4/50, Train Loss: 2582.74116, Validation Loss: 2485.55335\n",
            "Decrease in Validation Loss: (2649.002981 to 2485.553348). Saving Model...\n",
            "Epoch: 5/50, Train Loss: 2425.47013, Validation Loss: 2336.05599\n",
            "Decrease in Validation Loss: (2485.553348 to 2336.055995). Saving Model...\n",
            "Epoch: 6/50, Train Loss: 2281.60457, Validation Loss: 2199.18108\n",
            "Decrease in Validation Loss: (2336.055995 to 2199.181078). Saving Model...\n",
            "Epoch: 7/50, Train Loss: 2149.84808, Validation Loss: 2073.84072\n",
            "Decrease in Validation Loss: (2199.181078 to 2073.840721). Saving Model...\n",
            "Epoch: 8/50, Train Loss: 2029.16792, Validation Loss: 1959.05561\n",
            "Decrease in Validation Loss: (2073.840721 to 1959.055613). Saving Model...\n",
            "Epoch: 9/50, Train Loss: 1918.62253, Validation Loss: 1853.94175\n",
            "Decrease in Validation Loss: (1959.055613 to 1853.941752). Saving Model...\n",
            "Epoch: 10/50, Train Loss: 1817.36481, Validation Loss: 1757.82230\n",
            "Decrease in Validation Loss: (1853.941752 to 1757.822297). Saving Model...\n",
            "Epoch: 11/50, Train Loss: 1724.74915, Validation Loss: 1669.76715\n",
            "Decrease in Validation Loss: (1757.822297 to 1669.767151). Saving Model...\n",
            "Epoch: 12/50, Train Loss: 1639.88137, Validation Loss: 1589.21727\n",
            "Decrease in Validation Loss: (1669.767151 to 1589.217270). Saving Model...\n",
            "Epoch: 13/50, Train Loss: 1562.22084, Validation Loss: 1515.45484\n",
            "Decrease in Validation Loss: (1589.217270 to 1515.454840). Saving Model...\n",
            "Epoch: 14/50, Train Loss: 1491.08839, Validation Loss: 1447.86410\n",
            "Decrease in Validation Loss: (1515.454840 to 1447.864095). Saving Model...\n",
            "Epoch: 15/50, Train Loss: 1425.87734, Validation Loss: 1385.98631\n",
            "Decrease in Validation Loss: (1447.864095 to 1385.986311). Saving Model...\n",
            "Epoch: 16/50, Train Loss: 1366.16590, Validation Loss: 1329.40010\n",
            "Decrease in Validation Loss: (1385.986311 to 1329.400098). Saving Model...\n",
            "Epoch: 17/50, Train Loss: 1311.53811, Validation Loss: 1277.53084\n",
            "Decrease in Validation Loss: (1329.400098 to 1277.530838). Saving Model...\n",
            "Epoch: 18/50, Train Loss: 1261.44780, Validation Loss: 1230.10088\n",
            "Decrease in Validation Loss: (1277.530838 to 1230.100884). Saving Model...\n",
            "Epoch: 19/50, Train Loss: 1215.62328, Validation Loss: 1186.69946\n",
            "Decrease in Validation Loss: (1230.100884 to 1186.699461). Saving Model...\n",
            "Epoch: 20/50, Train Loss: 1173.67954, Validation Loss: 1146.94640\n",
            "Decrease in Validation Loss: (1186.699461 to 1146.946400). Saving Model...\n",
            "Epoch: 21/50, Train Loss: 1135.24197, Validation Loss: 1110.53737\n",
            "Decrease in Validation Loss: (1146.946400 to 1110.537366). Saving Model...\n",
            "Epoch: 22/50, Train Loss: 1100.02396, Validation Loss: 1077.27189\n",
            "Decrease in Validation Loss: (1110.537366 to 1077.271890). Saving Model...\n",
            "Epoch: 23/50, Train Loss: 1067.83084, Validation Loss: 1046.82684\n",
            "Decrease in Validation Loss: (1077.271890 to 1046.826843). Saving Model...\n",
            "Epoch: 24/50, Train Loss: 1038.35530, Validation Loss: 1018.89582\n",
            "Decrease in Validation Loss: (1046.826843 to 1018.895817). Saving Model...\n",
            "Epoch: 25/50, Train Loss: 1011.29546, Validation Loss: 993.35158\n",
            "Decrease in Validation Loss: (1018.895817 to 993.351580). Saving Model...\n",
            "Epoch: 26/50, Train Loss: 986.54043, Validation Loss: 969.99503\n",
            "Decrease in Validation Loss: (993.351580 to 969.995028). Saving Model...\n",
            "Epoch: 27/50, Train Loss: 963.89221, Validation Loss: 948.61242\n",
            "Decrease in Validation Loss: (969.995028 to 948.612419). Saving Model...\n",
            "Epoch: 28/50, Train Loss: 943.14512, Validation Loss: 929.00189\n",
            "Decrease in Validation Loss: (948.612419 to 929.001890). Saving Model...\n",
            "Epoch: 29/50, Train Loss: 924.10551, Validation Loss: 911.09806\n",
            "Decrease in Validation Loss: (929.001890 to 911.098058). Saving Model...\n",
            "Epoch: 30/50, Train Loss: 906.71252, Validation Loss: 894.69739\n",
            "Decrease in Validation Loss: (911.098058 to 894.697385). Saving Model...\n",
            "Epoch: 31/50, Train Loss: 890.76959, Validation Loss: 879.67647\n",
            "Decrease in Validation Loss: (894.697385 to 879.676473). Saving Model...\n",
            "Epoch: 32/50, Train Loss: 876.15767, Validation Loss: 865.95763\n",
            "Decrease in Validation Loss: (879.676473 to 865.957626). Saving Model...\n",
            "Epoch: 33/50, Train Loss: 862.80351, Validation Loss: 853.38462\n",
            "Decrease in Validation Loss: (865.957626 to 853.384616). Saving Model...\n",
            "Epoch: 34/50, Train Loss: 850.55464, Validation Loss: 841.91423\n",
            "Decrease in Validation Loss: (853.384616 to 841.914229). Saving Model...\n",
            "Epoch: 35/50, Train Loss: 839.37327, Validation Loss: 831.41148\n",
            "Decrease in Validation Loss: (841.914229 to 831.411480). Saving Model...\n",
            "Epoch: 36/50, Train Loss: 829.12522, Validation Loss: 821.79198\n",
            "Decrease in Validation Loss: (831.411480 to 821.791983). Saving Model...\n",
            "Epoch: 37/50, Train Loss: 819.72997, Validation Loss: 812.96445\n",
            "Decrease in Validation Loss: (821.791983 to 812.964448). Saving Model...\n",
            "Epoch: 38/50, Train Loss: 811.10246, Validation Loss: 804.92238\n",
            "Decrease in Validation Loss: (812.964448 to 804.922385). Saving Model...\n",
            "Epoch: 39/50, Train Loss: 803.23468, Validation Loss: 797.57015\n",
            "Decrease in Validation Loss: (804.922385 to 797.570149). Saving Model...\n",
            "Epoch: 40/50, Train Loss: 796.03584, Validation Loss: 790.82985\n",
            "Decrease in Validation Loss: (797.570149 to 790.829853). Saving Model...\n",
            "Epoch: 41/50, Train Loss: 789.42803, Validation Loss: 784.65346\n",
            "Decrease in Validation Loss: (790.829853 to 784.653461). Saving Model...\n",
            "Epoch: 42/50, Train Loss: 783.36680, Validation Loss: 779.02270\n",
            "Decrease in Validation Loss: (784.653461 to 779.022696). Saving Model...\n",
            "Epoch: 43/50, Train Loss: 777.83499, Validation Loss: 773.87098\n",
            "Decrease in Validation Loss: (779.022696 to 773.870982). Saving Model...\n",
            "Epoch: 44/50, Train Loss: 772.76697, Validation Loss: 769.14413\n",
            "Decrease in Validation Loss: (773.870982 to 769.144125). Saving Model...\n",
            "Epoch: 45/50, Train Loss: 768.11257, Validation Loss: 764.83931\n",
            "Decrease in Validation Loss: (769.144125 to 764.839313). Saving Model...\n",
            "Epoch: 46/50, Train Loss: 763.86823, Validation Loss: 760.87349\n",
            "Decrease in Validation Loss: (764.839313 to 760.873488). Saving Model...\n",
            "Epoch: 47/50, Train Loss: 759.95339, Validation Loss: 757.26573\n",
            "Decrease in Validation Loss: (760.873488 to 757.265727). Saving Model...\n",
            "Epoch: 48/50, Train Loss: 756.38555, Validation Loss: 753.96888\n",
            "Decrease in Validation Loss: (757.265727 to 753.968876). Saving Model...\n",
            "Epoch: 49/50, Train Loss: 753.12051, Validation Loss: 750.94422\n",
            "Decrease in Validation Loss: (753.968876 to 750.944221). Saving Model...\n",
            "Epoch: 50/50, Train Loss: 750.12176, Validation Loss: 748.17196\n",
            "Decrease in Validation Loss: (750.944221 to 748.171961). Saving Model...\n",
            "\n",
            "Time Taken for Training: 04:09:47.70\n",
            "\n",
            "Saving model losses to drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m3-tTHJ9ETK",
        "outputId": "c6454a0b-7853-43f9-e1d2-9a4475d4739f"
      },
      "source": [
        "model = BaselineCNN()\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "print(\"Loss Function:\\n\", criterion)\n",
        "# Optimizer\n",
        "print(\"\")\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
        "print(\"Optimizer:\\n\", optimizer)\n",
        "\n",
        "epochs = 50\n",
        "model_name = \"baseline_CNN_ADAM_0.0001\"\n",
        "losses_filename = \"{}_losses\".format(model_name)\n",
        "\n",
        "model_losses = train(model, trainloader, validloader, epochs, criterion, optimizer, device, model_name, losses_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaselineCNN(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=25088, out_features=32, bias=True)\n",
            "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n",
            "Loss Function:\n",
            " MSELoss()\n",
            "\n",
            "Optimizer:\n",
            " Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0001\n",
            "    weight_decay: 0\n",
            ")\n",
            "Epoch: 1/50, Train Loss: 865.84694, Validation Loss: 477.09428\n",
            "Decrease in Validation Loss: (inf to 477.094276). Saving Model...\n",
            "Epoch: 2/50, Train Loss: 499.46074, Validation Loss: 421.72203\n",
            "Decrease in Validation Loss: (477.094276 to 421.722027). Saving Model...\n",
            "Epoch: 3/50, Train Loss: 474.41084, Validation Loss: 415.51953\n",
            "Decrease in Validation Loss: (421.722027 to 415.519534). Saving Model...\n",
            "Epoch: 4/50, Train Loss: 450.16874, Validation Loss: 366.08014\n",
            "Decrease in Validation Loss: (415.519534 to 366.080136). Saving Model...\n",
            "Epoch: 5/50, Train Loss: 410.84650, Validation Loss: 329.08991\n",
            "Decrease in Validation Loss: (366.080136 to 329.089906). Saving Model...\n",
            "Epoch: 6/50, Train Loss: 372.87890, Validation Loss: 288.81213\n",
            "Decrease in Validation Loss: (329.089906 to 288.812135). Saving Model...\n",
            "Epoch: 7/50, Train Loss: 326.72140, Validation Loss: 245.29165\n",
            "Decrease in Validation Loss: (288.812135 to 245.291647). Saving Model...\n",
            "Epoch: 8/50, Train Loss: 305.25169, Validation Loss: 252.75853\n",
            "Epoch: 9/50, Train Loss: 294.25650, Validation Loss: 217.21684\n",
            "Decrease in Validation Loss: (245.291647 to 217.216839). Saving Model...\n",
            "Epoch: 10/50, Train Loss: 280.23186, Validation Loss: 198.05184\n",
            "Decrease in Validation Loss: (217.216839 to 198.051837). Saving Model...\n",
            "Epoch: 11/50, Train Loss: 279.29955, Validation Loss: 208.42240\n",
            "Epoch: 12/50, Train Loss: 277.70611, Validation Loss: 193.29510\n",
            "Decrease in Validation Loss: (198.051837 to 193.295103). Saving Model...\n",
            "Epoch: 13/50, Train Loss: 273.25367, Validation Loss: 188.24907\n",
            "Decrease in Validation Loss: (193.295103 to 188.249067). Saving Model...\n",
            "Epoch: 14/50, Train Loss: 266.74183, Validation Loss: 184.69516\n",
            "Decrease in Validation Loss: (188.249067 to 184.695157). Saving Model...\n",
            "Epoch: 15/50, Train Loss: 265.55682, Validation Loss: 182.88182\n",
            "Decrease in Validation Loss: (184.695157 to 182.881824). Saving Model...\n",
            "Epoch: 16/50, Train Loss: 262.68030, Validation Loss: 181.78052\n",
            "Decrease in Validation Loss: (182.881824 to 181.780519). Saving Model...\n",
            "Epoch: 17/50, Train Loss: 256.74438, Validation Loss: 185.54020\n",
            "Epoch: 18/50, Train Loss: 258.17181, Validation Loss: 181.41380\n",
            "Decrease in Validation Loss: (181.780519 to 181.413800). Saving Model...\n",
            "Epoch: 19/50, Train Loss: 254.85825, Validation Loss: 175.90060\n",
            "Decrease in Validation Loss: (181.413800 to 175.900604). Saving Model...\n",
            "Epoch: 20/50, Train Loss: 253.63571, Validation Loss: 197.13021\n",
            "Epoch: 21/50, Train Loss: 250.02669, Validation Loss: 178.52019\n",
            "Epoch: 22/50, Train Loss: 251.17459, Validation Loss: 179.16765\n",
            "Epoch: 23/50, Train Loss: 246.91031, Validation Loss: 183.64151\n",
            "Epoch: 24/50, Train Loss: 247.67522, Validation Loss: 162.06991\n",
            "Decrease in Validation Loss: (175.900604 to 162.069914). Saving Model...\n",
            "Epoch: 25/50, Train Loss: 242.39840, Validation Loss: 160.55820\n",
            "Decrease in Validation Loss: (162.069914 to 160.558203). Saving Model...\n",
            "Epoch: 26/50, Train Loss: 244.21707, Validation Loss: 180.02737\n",
            "Epoch: 27/50, Train Loss: 241.09309, Validation Loss: 158.28511\n",
            "Decrease in Validation Loss: (160.558203 to 158.285112). Saving Model...\n",
            "Epoch: 28/50, Train Loss: 238.76962, Validation Loss: 177.77238\n",
            "Epoch: 29/50, Train Loss: 235.09602, Validation Loss: 159.80744\n",
            "Epoch: 30/50, Train Loss: 233.84322, Validation Loss: 158.15479\n",
            "Decrease in Validation Loss: (158.285112 to 158.154792). Saving Model...\n",
            "Epoch: 31/50, Train Loss: 231.05482, Validation Loss: 148.29847\n",
            "Decrease in Validation Loss: (158.154792 to 148.298471). Saving Model...\n",
            "Epoch: 32/50, Train Loss: 228.08656, Validation Loss: 146.89121\n",
            "Decrease in Validation Loss: (148.298471 to 146.891206). Saving Model...\n",
            "Epoch: 33/50, Train Loss: 226.75629, Validation Loss: 147.89098\n",
            "Epoch: 34/50, Train Loss: 223.96923, Validation Loss: 146.88031\n",
            "Decrease in Validation Loss: (146.891206 to 146.880310). Saving Model...\n",
            "Epoch: 35/50, Train Loss: 222.40455, Validation Loss: 138.53135\n",
            "Decrease in Validation Loss: (146.880310 to 138.531354). Saving Model...\n",
            "Epoch: 36/50, Train Loss: 224.90407, Validation Loss: 141.61735\n",
            "Epoch: 37/50, Train Loss: 221.61146, Validation Loss: 138.63739\n",
            "Epoch: 38/50, Train Loss: 217.40078, Validation Loss: 154.06459\n",
            "Epoch: 39/50, Train Loss: 214.52729, Validation Loss: 137.03249\n",
            "Decrease in Validation Loss: (138.531354 to 137.032485). Saving Model...\n",
            "Epoch: 40/50, Train Loss: 214.08808, Validation Loss: 129.71519\n",
            "Decrease in Validation Loss: (137.032485 to 129.715195). Saving Model...\n",
            "Epoch: 41/50, Train Loss: 211.66431, Validation Loss: 128.86604\n",
            "Decrease in Validation Loss: (129.715195 to 128.866040). Saving Model...\n",
            "Epoch: 42/50, Train Loss: 210.44626, Validation Loss: 125.97736\n",
            "Decrease in Validation Loss: (128.866040 to 125.977358). Saving Model...\n",
            "Epoch: 43/50, Train Loss: 209.60100, Validation Loss: 123.33107\n",
            "Decrease in Validation Loss: (125.977358 to 123.331072). Saving Model...\n",
            "Epoch: 44/50, Train Loss: 207.81768, Validation Loss: 129.37852\n",
            "Epoch: 45/50, Train Loss: 205.27107, Validation Loss: 126.26420\n",
            "Epoch: 46/50, Train Loss: 203.15949, Validation Loss: 121.25302\n",
            "Decrease in Validation Loss: (123.331072 to 121.253017). Saving Model...\n",
            "Epoch: 47/50, Train Loss: 204.07954, Validation Loss: 127.01404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJpG7tOI9EVQ"
      },
      "source": [
        "loss_text = \"\"\"\n",
        "\n",
        "Epoch: 1/50, Train Loss: 865.84694, Validation Loss: 477.09428\n",
        "Decrease in Validation Loss: (inf to 477.094276). Saving Model...\n",
        "Epoch: 2/50, Train Loss: 499.46074, Validation Loss: 421.72203\n",
        "Decrease in Validation Loss: (477.094276 to 421.722027). Saving Model...\n",
        "Epoch: 3/50, Train Loss: 474.41084, Validation Loss: 415.51953\n",
        "Decrease in Validation Loss: (421.722027 to 415.519534). Saving Model...\n",
        "Epoch: 4/50, Train Loss: 450.16874, Validation Loss: 366.08014\n",
        "Decrease in Validation Loss: (415.519534 to 366.080136). Saving Model...\n",
        "Epoch: 5/50, Train Loss: 410.84650, Validation Loss: 329.08991\n",
        "Decrease in Validation Loss: (366.080136 to 329.089906). Saving Model...\n",
        "Epoch: 6/50, Train Loss: 372.87890, Validation Loss: 288.81213\n",
        "Decrease in Validation Loss: (329.089906 to 288.812135). Saving Model...\n",
        "Epoch: 7/50, Train Loss: 326.72140, Validation Loss: 245.29165\n",
        "Decrease in Validation Loss: (288.812135 to 245.291647). Saving Model...\n",
        "Epoch: 8/50, Train Loss: 305.25169, Validation Loss: 252.75853\n",
        "Epoch: 9/50, Train Loss: 294.25650, Validation Loss: 217.21684\n",
        "Decrease in Validation Loss: (245.291647 to 217.216839). Saving Model...\n",
        "Epoch: 10/50, Train Loss: 280.23186, Validation Loss: 198.05184\n",
        "Decrease in Validation Loss: (217.216839 to 198.051837). Saving Model...\n",
        "Epoch: 11/50, Train Loss: 279.29955, Validation Loss: 208.42240\n",
        "Epoch: 12/50, Train Loss: 277.70611, Validation Loss: 193.29510\n",
        "Decrease in Validation Loss: (198.051837 to 193.295103). Saving Model...\n",
        "Epoch: 13/50, Train Loss: 273.25367, Validation Loss: 188.24907\n",
        "Decrease in Validation Loss: (193.295103 to 188.249067). Saving Model...\n",
        "Epoch: 14/50, Train Loss: 266.74183, Validation Loss: 184.69516\n",
        "Decrease in Validation Loss: (188.249067 to 184.695157). Saving Model...\n",
        "Epoch: 15/50, Train Loss: 265.55682, Validation Loss: 182.88182\n",
        "Decrease in Validation Loss: (184.695157 to 182.881824). Saving Model...\n",
        "Epoch: 16/50, Train Loss: 262.68030, Validation Loss: 181.78052\n",
        "Decrease in Validation Loss: (182.881824 to 181.780519). Saving Model...\n",
        "Epoch: 17/50, Train Loss: 256.74438, Validation Loss: 185.54020\n",
        "Epoch: 18/50, Train Loss: 258.17181, Validation Loss: 181.41380\n",
        "Decrease in Validation Loss: (181.780519 to 181.413800). Saving Model...\n",
        "Epoch: 19/50, Train Loss: 254.85825, Validation Loss: 175.90060\n",
        "Decrease in Validation Loss: (181.413800 to 175.900604). Saving Model...\n",
        "Epoch: 20/50, Train Loss: 253.63571, Validation Loss: 197.13021\n",
        "Epoch: 21/50, Train Loss: 250.02669, Validation Loss: 178.52019\n",
        "Epoch: 22/50, Train Loss: 251.17459, Validation Loss: 179.16765\n",
        "Epoch: 23/50, Train Loss: 246.91031, Validation Loss: 183.64151\n",
        "Epoch: 24/50, Train Loss: 247.67522, Validation Loss: 162.06991\n",
        "Decrease in Validation Loss: (175.900604 to 162.069914). Saving Model...\n",
        "Epoch: 25/50, Train Loss: 242.39840, Validation Loss: 160.55820\n",
        "Decrease in Validation Loss: (162.069914 to 160.558203). Saving Model...\n",
        "Epoch: 26/50, Train Loss: 244.21707, Validation Loss: 180.02737\n",
        "Epoch: 27/50, Train Loss: 241.09309, Validation Loss: 158.28511\n",
        "Decrease in Validation Loss: (160.558203 to 158.285112). Saving Model...\n",
        "Epoch: 28/50, Train Loss: 238.76962, Validation Loss: 177.77238\n",
        "Epoch: 29/50, Train Loss: 235.09602, Validation Loss: 159.80744\n",
        "Epoch: 30/50, Train Loss: 233.84322, Validation Loss: 158.15479\n",
        "Decrease in Validation Loss: (158.285112 to 158.154792). Saving Model...\n",
        "Epoch: 31/50, Train Loss: 231.05482, Validation Loss: 148.29847\n",
        "Decrease in Validation Loss: (158.154792 to 148.298471). Saving Model...\n",
        "Epoch: 32/50, Train Loss: 228.08656, Validation Loss: 146.89121\n",
        "Decrease in Validation Loss: (148.298471 to 146.891206). Saving Model...\n",
        "Epoch: 33/50, Train Loss: 226.75629, Validation Loss: 147.89098\n",
        "Epoch: 34/50, Train Loss: 223.96923, Validation Loss: 146.88031\n",
        "Decrease in Validation Loss: (146.891206 to 146.880310). Saving Model...\n",
        "Epoch: 35/50, Train Loss: 222.40455, Validation Loss: 138.53135\n",
        "Decrease in Validation Loss: (146.880310 to 138.531354). Saving Model...\n",
        "Epoch: 36/50, Train Loss: 224.90407, Validation Loss: 141.61735\n",
        "Epoch: 37/50, Train Loss: 221.61146, Validation Loss: 138.63739\n",
        "Epoch: 38/50, Train Loss: 217.40078, Validation Loss: 154.06459\n",
        "Epoch: 39/50, Train Loss: 214.52729, Validation Loss: 137.03249\n",
        "Decrease in Validation Loss: (138.531354 to 137.032485). Saving Model...\n",
        "Epoch: 40/50, Train Loss: 214.08808, Validation Loss: 129.71519\n",
        "Decrease in Validation Loss: (137.032485 to 129.715195). Saving Model...\n",
        "Epoch: 41/50, Train Loss: 211.66431, Validation Loss: 128.86604\n",
        "Decrease in Validation Loss: (129.715195 to 128.866040). Saving Model...\n",
        "Epoch: 42/50, Train Loss: 210.44626, Validation Loss: 125.97736\n",
        "Decrease in Validation Loss: (128.866040 to 125.977358). Saving Model...\n",
        "Epoch: 43/50, Train Loss: 209.60100, Validation Loss: 123.33107\n",
        "Decrease in Validation Loss: (125.977358 to 123.331072). Saving Model...\n",
        "Epoch: 44/50, Train Loss: 207.81768, Validation Loss: 129.37852\n",
        "Epoch: 45/50, Train Loss: 205.27107, Validation Loss: 126.26420\n",
        "Epoch: 46/50, Train Loss: 203.15949, Validation Loss: 121.25302\n",
        "Decrease in Validation Loss: (123.331072 to 121.253017). Saving Model...\n",
        "Epoch: 47/50, Train Loss: 204.07954, Validation Loss: 127.01404\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xzc7-Qg9EXr"
      },
      "source": [
        "loss_text_list = loss_text.split(\"\\n\")\n",
        "loss_text_list = [text for text in loss_text_list if text.startswith(\"Epoch:\")]\n",
        "loss_text_list = [text.split(\",\") for text in loss_text_list]\n",
        "# loss_text_list\n",
        "losses = {\"train_loss\": [], \"valid_loss\": []}\n",
        "for i in loss_text_list:\n",
        "  losses[\"train_loss\"].append(float(i[1].split(\":\")[1].strip()))\n",
        "  losses[\"valid_loss\"].append(float(i[2].split(\":\")[1].strip()))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPfTPHb7xEBH",
        "outputId": "28935f1a-bf28-4674-8605-5bcc5f51ee61"
      },
      "source": [
        "model_name = \"baseline_CNN_ADAM_0.0001\"\n",
        "losses_filename = \"{}_losses\".format(model_name)\n",
        "write_model_losses(losses_filename, losses)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model losses to drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-poP7bExqSVB"
      },
      "source": [
        "losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "uzN7zyI9LrRx",
        "outputId": "1361067f-43f7-413e-c46f-c6f020c8f17d"
      },
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "plt.title(\"Loss over Epochs\")\n",
        "plt.plot(losses[\"train_loss\"])\n",
        "plt.plot(losses[\"valid_loss\"])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Losses\")\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
        "plt.grid(\"True\")\n",
        "plt.style.use(\"seaborn-deep\")\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJiKynza6Cl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319d186a-a6d9-4778-815d-c9ed3cee0830"
      },
      "source": [
        "  print(torch.cuda.memory_summary(device=None, abbreviated=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   14935 MB |   14987 MB |   17544 MB |    2608 MB |\n",
            "|       from large pool |   14932 MB |   14984 MB |   17535 MB |    2603 MB |\n",
            "|       from small pool |       3 MB |       3 MB |       8 MB |       5 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   14935 MB |   14987 MB |   17544 MB |    2608 MB |\n",
            "|       from large pool |   14932 MB |   14984 MB |   17535 MB |    2603 MB |\n",
            "|       from small pool |       3 MB |       3 MB |       8 MB |       5 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   15114 MB |   15220 MB |   15220 MB |  108544 KB |\n",
            "|       from large pool |   15110 MB |   15216 MB |   15216 MB |  108544 KB |\n",
            "|       from small pool |       4 MB |       4 MB |       4 MB |       0 KB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  182297 KB |  562875 KB |    1491 MB |    1313 MB |\n",
            "|       from large pool |  181568 KB |  561024 KB |    1480 MB |    1303 MB |\n",
            "|       from small pool |     729 KB |    2238 KB |      11 MB |      10 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     107    |     107    |     187    |      80    |\n",
            "|       from large pool |      61    |      61    |      75    |      14    |\n",
            "|       from small pool |      46    |      46    |     112    |      66    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     107    |     107    |     187    |      80    |\n",
            "|       from large pool |      61    |      61    |      75    |      14    |\n",
            "|       from small pool |      46    |      46    |     112    |      66    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      46    |      47    |      47    |       1    |\n",
            "|       from large pool |      44    |      45    |      45    |       1    |\n",
            "|       from small pool |       2    |       2    |       2    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      11    |      15    |      45    |      34    |\n",
            "|       from large pool |       9    |      10    |      19    |      10    |\n",
            "|       from small pool |       2    |       6    |      26    |      24    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pvKFM6xQfGb"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y91ASexjLca2",
        "outputId": "973b3743-800a-4f26-94ce-5ba2c76c8dbb"
      },
      "source": [
        "best_model = BaselineCNN()\n",
        "model_name = \"baseline_CNN_SGD\"\n",
        "model_path = \"/content/drive/MyDrive/DS5500 Data/baselineCNN_best_model_1.pt\"\n",
        "best_model = loadModel(model_path, best_model)\n",
        "best_model.to(device)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaselineCNN(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=25088, out_features=32, bias=True)\n",
              "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRqwEb-c2j_j",
        "outputId": "3c49df51-382c-4386-f38b-1306fb605ba6"
      },
      "source": [
        "best_model.fc1.weight"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0004, -0.0029, -0.0106,  ..., -0.0094, -0.0062, -0.0046],\n",
              "        [-0.0074, -0.0081, -0.0016,  ..., -0.0045, -0.0066, -0.0053],\n",
              "        [-0.0118, -0.0004, -0.0024,  ..., -0.0107, -0.0122,  0.0051],\n",
              "        ...,\n",
              "        [-0.0016, -0.0046, -0.0094,  ..., -0.0028, -0.0107, -0.0024],\n",
              "        [-0.0322,  0.0044, -0.0129,  ..., -0.0104, -0.0207,  0.0194],\n",
              "        [-0.0258, -0.0116,  0.0162,  ...,  0.0228,  0.0104, -0.0021]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "aHGJcIU3MgFC",
        "outputId": "e36ecadf-d015-42c6-d53d-75d38ef06fcf"
      },
      "source": [
        "# testloader = DataLoader(testset, batch_size=, shuffle=True)\n",
        "predictions, total_MSE_loss, total_RMSE_loss = model_evaluation(validloader, best_model)\n",
        "res_df = pd.concat([valid_metadata, predictions], axis=1)\n",
        "plot_predictions(valid_metadata.wind_speed[0], res_df)\n",
        "print(total_MSE_loss,total_RMSE_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-921e752fb752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# testloader = DataLoader(testset, batch_size=, shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_MSE_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_RMSE_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mres_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwind_speed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_MSE_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_RMSE_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f5dde1d6b0ff>\u001b[0m in \u001b[0;36mmodel_evaluation\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-06cfe27283ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# add sequence of convolutional and max pooling layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 15.90 GiB total capacity; 14.87 GiB already allocated; 27.75 MiB free; 14.90 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "BCzPI1njbwgI",
        "outputId": "f25c822c-964f-448c-efa1-c44a997bbc30"
      },
      "source": [
        "predictions, total_MSE_loss, total_RMSE_loss = model_evaluation(validloader, best_model, criterion, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-35c2e0994c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_MSE_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_RMSE_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-d2b839643ae4>\u001b[0m in \u001b[0;36mmodel_evaluation\u001b[0;34m(dataloader, model, criterion, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-06cfe27283ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# add sequence of convolutional and max pooling layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 15.90 GiB total capacity; 14.58 GiB already allocated; 175.75 MiB free; 14.76 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aICR2M3MgPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01627cc5-9a7e-4ab1-c358-b95256b2d8c2"
      },
      "source": [
        "ts = torch.tensor([[1, 2, 3], [1, 2, 3]])\n",
        "ts.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21aGuZpAeqrw",
        "outputId": "9c435239-f070-4815-8800-8c4e17c1c8a4"
      },
      "source": [
        "ts.cpu()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJVKFykae5FA"
      },
      "source": [
        "train_metadata.storm_id.str.split(\"_\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "1sf_6Usr-i3J",
        "outputId": "3d5bfe6e-6a4d-4e24-b2a7-cba16d23c7cc"
      },
      "source": [
        "train_metadata.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>storm_id</th>\n",
              "      <th>relative_time</th>\n",
              "      <th>ocean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abs_000</td>\n",
              "      <td>43</td>\n",
              "      <td>abs</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abs_001</td>\n",
              "      <td>44</td>\n",
              "      <td>abs</td>\n",
              "      <td>1800</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abs_002</td>\n",
              "      <td>45</td>\n",
              "      <td>abs</td>\n",
              "      <td>5400</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abs_003</td>\n",
              "      <td>52</td>\n",
              "      <td>abs</td>\n",
              "      <td>17999</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abs_004</td>\n",
              "      <td>53</td>\n",
              "      <td>abs</td>\n",
              "      <td>19799</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  wind_speed storm_id  relative_time  ocean\n",
              "0  abs_000  43          abs      0              2    \n",
              "1  abs_001  44          abs      1800           2    \n",
              "2  abs_002  45          abs      5400           2    \n",
              "3  abs_003  52          abs      17999          2    \n",
              "4  abs_004  53          abs      19799          2    "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQW0tchE2UDJ"
      },
      "source": [
        "def get_data\n",
        "d = dict()\n",
        "for i in range(0, train_metadata2.shape[0]):\n",
        "  i2 = i-9\n",
        "  i3 = i2-9\n",
        "  if i3 > 0 and i2 > 0:\n",
        "    lis = [train_metadata2.image_path[i3], train_metadata2.image_path[i2], train_metadata2.image_path[i]]\n",
        "    storm_id = train_metadata2.storm_id[i3]\n",
        "    wind_speed = train_metadata2.wind_speed[i3]\n",
        "\n",
        "    if storm_id not in d.keys():\n",
        "      d[storm_id] = {\"image_list\": [(lis, wind_speed)]}\n",
        "    else:\n",
        "      d[storm_id][\"image_list\"].append((lis, wind_speed))\n",
        "      # d[storm_id][\"wind_speed\"].append(wind_speed)\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLc7sT0X8_Hl",
        "outputId": "f73147dd-631d-4c10-992c-e89637a30223"
      },
      "source": [
        "d[\"abs\"][\"image_list\"][]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['/content//nasa_tropical_storm_competition_train_source/nasa_tropical_storm_competition_train_source_abs_003/image.jpg',\n",
              "  '/content//nasa_tropical_storm_competition_train_source/nasa_tropical_storm_competition_train_source_abs_013/image.jpg',\n",
              "  '/content//nasa_tropical_storm_competition_train_source/nasa_tropical_storm_competition_train_source_abs_027/image.jpg'],\n",
              " 52)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqPYwaHn90im"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}